---
title: "Homework 5"
subtitle: "Bivariate Statistics One-way ANOVA and Regression Analysis"
date: 2024-11-22
date-format: long
author: 
  - Andri Setiyawan
  - Benedikt Meyer
  - Yosep Dwi Kristanto
format: pdf
number-sections: true
editor: visual
execute: 
  echo: false
editor_options: 
  chunk_output_type: console
---

```{r}
#| message: false

library(tidyverse)
library(haven)
library(knitr)
library(kableExtra)
library(ggforce)
library(ggpubr)
library(rstatix)
library(ggstatsplot)
library(broom)
library(ggtext)
```

::: {.callout-tip icon="false"}
# The Data Detective: Alex’s Adventures in Numbers

*The following story was created with the assistance of ChatGPT, and the full prompt and conversation used to develop it can be accessed at <https://chatgpt.com/share/6740a6fc-d3f8-800a-a0dd-6a22eb523458>.*

------------------------------------------------------------------------

![](alex-the-statistician.jpg){fig-alt="A classroom scene where Alex, a passionate statistician, stands at the front, gesturing towards a graph on the board. The graph showcases data, possibly related to sales or exam performance. The students are seated, engaged, and inspired by the presentation. One student in the foreground is shown taking notes with a determined expression, emphasizing the impact of Alex's teaching." fig-align="center"}

Alex Martinez wasn’t your average statistician. Where others saw endless rows of numbers, Alex saw stories waiting to be told. Armed with a laptop, a passion for problem-solving, and an almost magical ability to make numbers come alive, Alex split their time between two very different worlds: a bustling sales company and a university brimming with curious students.

## Cracking the Sales Script Code {.unnumbered}

Alex’s first stop was the boardroom of Dynamic Sales Solutions, a company known for experimenting with creative ways to connect with customers. Their latest challenge? Figuring out which of their four sales scripts—dubbed Friendly Chat (Script A), Persuasive Pitch (Script B), Fact Frenzy (Script C), and Casual Catch-Up (Script D)—was most effective.

“We’ve got all this data from the past month,” said Carla, the sales manager, waving a stack of papers. “But we’re stumped on which script is truly the best.”

Alex grinned. “Let’s let the data do the talking.”

After hours of crunching numbers and running an analysis of variance (ANOVA), Alex gathered the team around. On the screen, a colorful bar chart appeared, with Script A towering over the rest.

“Here’s what we found,” Alex explained, pointing to the bars. “Script A—Friendly Chat—brought in the most revenue. It’s not just a little better; it’s significantly better. Scripts B and C did okay, but Script D—Casual Catch-Up—lagged behind.”

Carla frowned. “Why is Friendly Chat so effective?”

“It’s simple,” Alex said, clicking to a slide that summarized the findings. “Friendly Chat focuses on understanding customer needs. When sales reps actively listen and respond to customer concerns, they build trust. People are more likely to buy when they feel heard.”

The sales team buzzed with excitement. “So we should use Script A more often?” asked one rep.

“Exactly,” Alex nodded. “But remember, even the best script only works if you genuinely care about your customers. Numbers can guide us, but human connection seals the deal.”

## Unlocking Academic Success {.unnumbered}

After a quick lunch, Alex headed to their next challenge: a university seminar where students were eager to understand what made some of them excel in exams while others struggled.

Professor Tanaka greeted Alex warmly. “Our students are curious about how their habits impact their grades. Can you help demystify it for them?”

Alex nodded, pulling up a scatter plot and a 3D graph showing the results of their analysis. “We looked at two factors,” Alex began, addressing the class. “First, how many hours you spend revising each week. Second, your A-level entry points—basically, your academic background when you started here. Together, these predict your exam scores pretty well.”

A student raised her hand. “How much do study hours really matter?”

“Great question,” Alex replied. “For every extra hour you spend studying, your score increases by 0.48 points on average. That might not seem like much, but it adds up. For example, if you study five more hours, you’ll gain about 2.4 points. That could bump you from a B to an A!”

Another student asked, “What about A-levels? Are they more important than studying?”

“Well, each additional A-level entry point adds about 1.99 points to your score,” Alex explained. “But here’s the good news: no matter where you start, studying consistently makes a difference. Think of your A-levels as a foundation. The stronger it is, the easier it is to build on. But even with a shaky foundation, hard work can help you climb higher.”

The students leaned forward, clearly inspired.

“Let me put it this way,” Alex said with a smile. “Imagine you’re planting a garden. Your A-levels are the soil. The richer the soil, the better your plants will grow. But watering the plants—your study hours—matters just as much. If you take care of the garden, it will bloom.”

## Inspiring the Future {.unnumbered}

After the seminar, a student named Jamie approached Alex. “I always thought I wasn’t smart enough to do well,” Jamie admitted. “But now I see that my effort counts too.”

Alex beamed. “Absolutely, Jamie. Numbers don’t lie: hard work and preparation make a huge difference. Keep at it, and you’ll surprise yourself.”

As Alex packed up for the day, they reflected on how different their two clients were but how similar their lessons had been. Whether it was choosing the best sales script or helping students excel, the secret lay in paying attention to the story behind the numbers.

Back at home, Alex typed up a blog post summarizing the day’s work. “Data is more than just numbers,” they wrote. “It’s a tool to understand the world, solve problems, and make better decisions. Whether you’re running a business or studying for an exam, remember: effort, curiosity, and a little data can take you a long way.”

The post ended with a simple but powerful message: “Hard work pays off. Numbers prove it.”
:::

# Telemarketing {.appendix}

## Data Exploration

```{r}
telemarketing <- read_sav("Telemarketing.sav")
telemarketing <- telemarketing |> 
  mutate(
    sales_pitch = as_factor(sales_pitch),
    industry = as_factor(industry),
    region = as_factor(region)
  )
```

@tbl-summary-telemarketing shows that average revenue and variability differ across the four sales pitches, with Script A generating the highest average revenue and Script D the lowest.

```{r}
#| label: tbl-summary-telemarketing
#| tbl-cap: "Summary statistics for `revenue` (n, mean, and standard deviation) across different `sales_pitch` in the telemarketing data"

telemarketing |> 
  drop_na() |> 
  group_by(sales_pitch) |> 
  summarise(
    n = n(),
    avg_revenue = mean(revenue),
    sd_avenue = sd(revenue)
  ) |> 
  kbl(
    col.names = c("sales_pitch", "n", "M", "SD")
  ) |> 
  kable_styling()
```

The distribution of `revenue` across the four `sales_pitch` (Script A, Script B, Script C, and Script D) is visually summarized using violin plots combined with boxplots, as shown in @fig-dist-telemarketing.

```{r}
#| label: fig-dist-telemarketing
#| fig-cap: "Distribution of `revenue` across `sales_pitch` (Script A, Script B, Script C, and Script D) as illustrated by violin and boxplots."
#| fig-asp: 0.5625

telemarketing |> 
  drop_na() |> 
  ggplot(aes(
    x = sales_pitch,
    y = revenue
  )) + 
  geom_point(
    aes(color = sales_pitch),
    show.legend = FALSE,
    position = position_jitter(width = .1),
    size = 2,
    alpha = .5
  ) + 
  geom_violin(
    alpha = .3,
    width = .6,
    show.legend = FALSE
  ) + 
  geom_boxplot(
    width = .4,
    alpha = 0
  ) + 
  stat_summary(
    fun = "mean", geom = "point",
    size = 5, col = "darkred"
  ) + 
  scale_color_brewer(palette = "Dark2") + 
  theme_minimal() + 
  labs(
    x = "Sales Pitch",
    y = "Revenue"
  )
```

## Assumption Checking

-   The outcome variable, revenue, is measured on a ratio scale.

-   The groups are mutually exclusive, with four distinct categories: Script A, Script B, Script C, and Script D.

-   The grouping variable consists of four levels: Script A, Script B, Script C, and Script D.

-   The QQ plots were used to assess the normality of `revenue` distributions for each `sales_pitch` (Script A, Script B, Script C, and Script D). See @fig-qq-plot-telemarketing.

    ```{r}
    #| label: fig-qq-plot-telemarketing
    #| fig-cap: "QQ plot of `revenue` across `sales_pitch`"
    #| fig-asp: 1

    telemarketing |> 
      drop_na() |> 
      ggqqplot(
        x = "revenue",
        color = "sales_pitch"
      ) + 
      facet_wrap(vars(sales_pitch)) + 
      scale_color_brewer(palette = "Dark2") + 
      scale_fill_brewer(palette = "Dark2") + 
      theme_minimal() + 
      theme(
        legend.position = "none"
      )
    ```

    From @fig-qq-plot-telemarketing, it appears that the `revenue` for each `sales_pitch` is likely drawn from a normally distributed population. This observation is supported by the Shapiro-Wilk test results presented in @tbl-normality-test-telemarketing.

    ```{r}
    #| label: tbl-normality-test-telemarketing
    #| tbl-cap: "Shapiro-Wilk test of normality for `revenue` across `sales_pitch`"

    telemarketing |> 
      group_by(sales_pitch) |> 
      shapiro_test(revenue) |> 
      kbl() |> 
      kable_styling()
    ```

    The p-value in @tbl-normality-test-telemarketing is greater than .05 suggests that the `revenue` in each `sales_pitch` follows a normal distribution.

-   @tbl-levene-test-telemarketing presents the results of Levene's test for homogeneity of variances of `revenue` across the different `sales_pitch` groups. Since the p-value is greater than .05, it suggests that the assumption of equal variances is met.

    ```{r}
    #| label: tbl-levene-test-telemarketing
    #| tbl-cap: "Results of Levene test for homogeneity of variance"

    telemarketing |> 
      levene_test(revenue ~ sales_pitch) |> 
      kbl() |> 
      kable_styling()
    ```

## Hypotheses

$H_0$: The average `revenue` is equal across all `sales_pitch` groups.

$H_1$: At least one pair of `sales_pitch` groups has a different average `revenue`.

## Calculating the $F$ statistic

The ANOVA results in @tbl-aov-result-telemarketing show an F-value of 42.505, testing the difference in average `revenue` across the `sales_pitch` groups.

```{r}
#| label: tbl-aov-result-telemarketing
#| tbl-cap: "ANOVA table testing the difference in average `revenue` across `sales_pitch` groups."

aov_telemarketing <- telemarketing |> 
  drop_na() |> 
  anova_test(revenue ~ sales_pitch)
aov_telemarketing |>  kbl() |> 
  kable_styling()
```

## Testing for the significance of $F$

@tbl-aov-result-telemarketing shows a p-value of `r aov_telemarketing$p |> signif(3)`, which is less than .05. A visualization of the p-value is presented in @fig-p-telemarketing.

```{r}
#| label: fig-p-telemarketing
#| fig-cap: "Theoretical $F$-distribution with degrees of freedom 3 and 1484, illustrating the tail area corresponding to the p-value"
#| fig-asp: 0.5625

F_telemarketing <- aov_telemarketing$F |> 
  as.numeric() |> 
  round(2)
ggplot(data.frame(x = c(0, 50)), aes(x)) +
  stat_function(
    fun = df,
    args = list(df1 = 3, df2 = 1484),
    linewidth = 1
  ) + 
  stat_function(
    fun = df,
    args = list(df1 = 3, df2 = 1484),
    linewidth = 2,
    color = "blue",
    xlim = c(F_telemarketing, 50)
  ) + 
  geom_vline(
    xintercept = F_telemarketing,
    linetype = "dashed"
  ) + 
  geom_textbox(
    x = 46,
    y = .125,
    label = "Tail area is too small to see",
    maxwidth = .2
  ) + 
  scale_x_continuous(
    breaks = c(
      F_telemarketing,
      0, 10, 20, 30, 50
    )
  ) + 
  labs(
    x = "F-value",
    y = "Density"
  ) +
  theme_minimal()
```

## Interpreting $F$

Assuming the null hypothesis is true, i.e., that the average `revenue` is equal across all `sales_pitch` groups, the sample yields an F-statistic of `r aov_telemarketing$F |> round(2)` and a p-value of `r aov_telemarketing$p |> signif(2)`, which is less than .05. As a result, we reject the null hypothesis, indicating that at least two groups in the `sales_pitch` have different average `revenue`.

## Effect Size

The generalized eta-squared (ges) from @tbl-aov-result-telemarketing of `r aov_telemarketing$ges |> round(3)` indicates that approximately `r aov_telemarketing$ges |> round(3)*100`% of the total variance in `revenue` can be attributed to differences across the `sales_pitch` groups. The value of `r aov_telemarketing$ges |> round(3)` suggests a medium effect size, indicating that group differences in `sales_pitch` explain a meaningful but not overwhelming portion of the variance in `revenue`.

## Post-hoc test

@tbl-pairwise-telemarketing displays the pairwise t-test result with Bonferroni-adjusted p-values. It indicates the statistical differences between the groups. These results suggest that there are significant differences in average of `revenue` between each pair of `sales_pitch` groups, which are highlighted in the pairwise comparisons.

```{r}
#| label: tbl-pairwise-telemarketing
#| tbl-cap: "Pairwise t-test results comparing revenue between sales_pitch groups, with Bonferroni-adjusted p-values"

# Get unique combinations of groups
sales_pitch_combn <- combn(sort(unique(telemarketing$sales_pitch)), 2, simplify = FALSE)

# Perform pairwise t-tests and extract t-values
pair_t_telemarketing <- do.call(rbind, lapply(sales_pitch_combn, function(groups) {
  group1 <- telemarketing$revenue[telemarketing$sales_pitch == groups[1]]
  group2 <- telemarketing$revenue[telemarketing$sales_pitch == groups[2]]
  t_test <- t.test(group1, group2) # Perform t-test
  
  # Create a row of results
  data.frame(
    Group_1 = groups[1],
    Group_2 = groups[2],
    t = t_test$statistic,
    df = t_test$parameter
  )
}))

# Getting adjusted p-value
pair_t_p_telemarketing <- pairwise.t.test(
  telemarketing$revenue,
  telemarketing$sales_pitch,
  p.adjust.method = "bonferroni"
)$p.value |> 
  as.data.frame() |> 
  rownames_to_column(var = "Group_2") |> 
  pivot_longer(
    cols = `Script A`:`Script C`,
    names_to = "Group_1",
    values_to = "p"
  ) |> 
  mutate(
    p = as.character(signif(p, 3))
  ) |> 
  drop_na() |> 
  select(Group_1, Group_2, p)

# Combining t and p
pair_telemarketing <- pair_t_telemarketing |> 
  left_join(
    pair_t_p_telemarketing,
    by = join_by(Group_1, Group_2)
  ) |> tibble()

# Making a table
pair_telemarketing |> 
  kbl(
    col.names = c(
      "Group 1", "Group 2",
      "t", "df", "p (Bonferroni-adj.)"
    )
  ) |> 
  kable_styling()
```

The results of the pairwise t-tests are visually represented in @fig-aov-post-hoc-telemarketing.

```{r}
#| label: fig-aov-post-hoc-telemarketing
#| fig-cap: "Violin plots and boxplots showing the distribution of revenue across the sales_pitch groups, with results of pairwise t-tests indicating differences between groups."
#| fig-asp: 1
telemarketing |> 
  ggbetweenstats(
    x = sales_pitch,
    y = revenue,
    type = "parametric",
    pairwise.display = "significant",
    p.adjust.method = "bonferroni",
    effsize.type = "eta",
    bf.message = FALSE,
    var.equal = TRUE,
    xlab = "Sales Pitch",
    ylab = "Revenue"
  )
```

## Reporting the Results

A one-way analysis of variance (ANOVA) was conducted to examine the effect of sales pitch on revenue. The results revealed a significant difference in average revenue across the four sales pitch groups, F(3, 1484) = 42.51, p \< .001, generalized eta-squared (ges) = .079, indicating that sales pitch had a medium effect on revenue.

Post-hoc comparisons were performed using pairwise t-tests with Bonferroni correction to identify specific group differences. The results indicated the following:

-   The average revenue for Script A (M = 2970.63, SD = 947.23) was significantly higher than for Script B (M = 2669.13, SD = 970.92), t(602.47) = 3.92, p \< .001; Script C (M = 2471.29, SD = 967.06), t(579.28) = 6.30, p \< .001; and Script D (M = 2215.65, SD = 943.00), t(555.56) = 10.87, p \< .001.

-   Similarly, Script B had significantly higher revenue than Script C, t(641.98) = 2.61, p = .0495, and Script D, t(728.91) = 6.92, p \< .001.

-   Lastly, Script C had significantly higher revenue than Script D, t(613.53) = 3.74, p = .00109.

These results suggest that Script A consistently led to the highest revenue, while Script D resulted in the lowest revenue among the four groups.

# Students' Performance {.appendix}

```{r}
exam <- read_sav("examrevision (1).sav")
```

## Data Exploration

@fig-corr-mat-exam presents the relationships between `score`, `hours`, `anxiety`, and `a_points` in the exam dataset using Pearson correlation coefficients. The strongest positive correlation is observed between `score` and `a_points` (r = 0.87), followed by the correlation between `score` and `hours` (r = 0.82). A weaker, negative correlation is found between `hours` and `anxiety` (r = -0.34), as well as between `score` and `anxiety` (r = -0.12).

```{r}
#| label: fig-corr-mat-exam
#| fig-cap: "Correlation matrix among all variables in exam data"
#| fig-asp: 0.75

ggcorrmat(
  data = exam,
  cor.vars = score:a_points,
  p.adjust.method = "none"
)
```

@tbl-models-summary-exam presents the results of regression analyses with `score` as the dependent variable and combinations of `hours`, `anxiety`, and `a_points` as independent variables.

```{r}
#| label: tbl-models-summary-exam
#| tbl-cap: "Summary table of regression analyses for all possible combinations of independent variables (`hours`, `anxiety`, and `a_points`) predicting `score` in the `exam` dataset"

# Dependent variable
dep_var <- "score"

# Independent variables
indep_vars <- c("hours", "anxiety", "a_points")

# Generate all possible combinations of independent variables (1, 2, or 3)
all_models <- map(
  1:length(indep_vars),
  ~ combn(indep_vars, .x, simplify = FALSE)
) |> 
  unlist(recursive = FALSE)

# Fit models and extract statistics
results_model <- map_dfr(all_models, function(vars) {
  # Build formula
  formula <- as.formula(paste(dep_var, "~", paste(vars, collapse = " + ")))
  
  # Fit model
  model <- lm(formula, data = exam)
  
  # Extract statistics
  glance_summary <- glance(model)
  
  # Return a summary row
  tibble(
    dependent_variable = dep_var,
    independent_variables = paste(vars, collapse = ", "),
    F_statistic = glance_summary$statistic,
    p_value = glance_summary$p.value,
    R_squared = glance_summary$r.squared,
    df = glance_summary$df,
    df_res = glance_summary$df.residual
  )
})

# Print the summary table
results_model |> 
  kbl() |> 
  kable_styling()
```

We choose `hours` and `a_points` as the independent variables for further analysis because they individually and together demonstrate strong predictive power for score. The model with these two variables accounts for 83% of the variance and has a high F-statistic, suggesting they are reliable predictors without the redundancy of including less impactful variables like `anxiety`.

## Hypotheses

$H_0$: All regression coefficients are equal to zero (except the intercept).

$H_1$: At least one of the regression coefficients is not equal to zero.

## Assumption Checking

**Correct specification of the model:** It is make sense to predict students' performance score (`score`) with how long they spent on revision (`hours`) and their A-level entry points (`a_points`).

**Linearity:** @fig-linearity-exam shows relationships between `score`, `hours` and `a_points`. From the figures, we can see that the relationship between `hours`, `a_points`, and `score` are linear.

```{r}
#| label: fig-linearity-exam
#| fig-cap: "Linearty verification"
#| fig-subcap:
#|   - "Relationship between `hours` and `score`"
#|   - "Relationship between `a_points` and `score`"
#| fig-asp: 1
#| layout-ncol: 2

exam |> 
  ggplot(aes(x = hours, y = score)) + 
  geom_point(
    size = 3
  ) + 
  stat_ellipse(
    level = .99
  ) + 
  theme_minimal()
exam |> 
  ggplot(aes(x = a_points, y = score)) + 
  geom_point(
    size = 3
  ) + 
  stat_ellipse(
    level = .99
  ) + 
  theme_minimal()
```

**Measurement and normality of dependence variable:** The dependence variable, i.e. `score`, is ratio. From the @fig-qq-plot-score-exam, we can assume that `score` sample is from normally distributed population.

```{r}
#| label: fig-qq-plot-score-exam
#| fig-cap: "Assessing normality for `score`"
ggqqplot(
  data = exam,
  x = "score"
) + 
  theme_minimal()
```

**Absence of multicollinearity:** Here is the correlation coefficient between `hours` and `a_points`.

```{r}
cor(
  exam$hours,
  exam$a_points
)
```

Since the correlation coefficient is less than .8, we infer that there is no multicollinearity between the independent variables.

**Normal distribution of residuals:** @fig-qq-plot-resid-exam shows that the residuals are normally distributed.

```{r}
#| label: fig-qq-plot-resid-exam
#| fig-cap: "Assessing the normality of residuals"
#| fig-asp: 0.5625

reg_model_exam <- lm(
  score ~ hours + a_points,
  data = exam
)
data_model_exam <- tibble(
  score = exam$score,
  fitted = reg_model_exam$fitted.values |> as.numeric(),
  residuals = reg_model_exam$residuals |> as.numeric()
)
ggqqplot(
  data = data_model_exam,
  x = "residuals"
) + 
  theme_minimal()
```

**Homoscedasticity:** @fig-homo-resid-exam shows that the residuals have equal variance across dependence variable.

```{r}
#| label: fig-homo-resid-exam
#| fig-cap: "Assessing homoscedacity of residuals"
#| fig-asp: 0.5625

data_model_exam |> 
  ggplot(aes(x = fitted, y = residuals)) + 
  geom_point() + 
  geom_hline(yintercept = 0) + 
  theme_minimal()
```

## Model

Below is the result of a multiple regression analysis examining the relationship between `hours` and `a_points` as predictors of `score`. The regression model was statistically significant, with an F-statistic of 42.09 and a p-value of 2.604e-07, indicating that the model as a whole explains a significant portion of the variation in the dependent variable, `score`.

```{r}
summary(reg_model_exam)
```

The coefficient for `hours` was .4765 (t = 2.703, p = .0151), indicating that for each additional hour, the `score` is expected to increase by .4765, holding `a_points` constant. The coefficient for `a_points` was 1.9945 (t = 3.997, p = .000933), suggesting that for each additional point in `a_points`, the `score` is expected to increase by 1.9945, holding `hours` constant. The residual standard error was 4.751, and the model explained 83.2% of the variance in score (R-squared = 0.832).

@fig-3d-model-exam presents the multiple regression model with `hours` and `a_points` as independent variables and `score` as the dependent variable. The surface represents the predicted score across different combinations of `hours` and `a_points`. The red line segments in the plot depict the residuals, which represent the vertical distance between the observed data points and the corresponding predicted values on the surface.

::: {#fig-3d-model-exam layout-ncol="2"}
![](3d_model_1.png){#fig-3d-model-exam-1}

![](3d_model_2.png){#fig-3d-model-exam-2}

3D visualization of the multiple regression model examining the relationship between `hours` and `a_points` as predictors of `score`
:::

## Reporting the Results

A multiple regression analysis was conducted to examine whether hours spent revising (`hours`) and A-level entry points (`a_points`) predicted exam scores (`score`). The results showed that the overall model was significant, F(2, 17) = 42.09, p \< .001, and explained 83.2% of the variance in exam scores (R² = .832, adjusted R² = .812).

Individually, both predictors significantly contributed to the model. For hours spent revising, b = .48, t(17) = 2.70, p = .015, indicating that for each additional hour spent revising, exam scores increased by an average of .48 points. For A-level entry points, b = 1.99, t(17) = 4.00, p \< .001, suggesting that each additional entry point was associated with an average increase of 1.99 points in exam scores. The intercept was not statistically significant, b = -3.93, t(17) = -0.48, p = .635.

The residual standard error was 4.75, indicating the average deviation of observed scores from predicted scores. These findings underscore the importance of study hours and prior academic achievement in predicting exam performance.
