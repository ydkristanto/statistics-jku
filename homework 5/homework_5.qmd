---
title: "Homework 5"
subtitle: "Bivariate Statistics One-way ANOVA and Regression Analysis"
date: 2024-11-14
date-format: long
author: 
  - Andri Setiyawan
  - Benedikt Meyer
  - Yosep Dwi Kristanto
format: pdf
number-sections: true
editor: visual
execute: 
  echo: false
editor_options: 
  chunk_output_type: console
---

```{r}
#| message: false

library(tidyverse)
library(haven)
library(knitr)
library(kableExtra)
library(ggforce)
library(ggpubr)
library(rstatix)
library(ggstatsplot)
library(broom)
```

::: {.callout-note icon="false"}
## Problems

1)  ANOVA: Launch SPSS and open the data file Telemarketing.sav

    *Assume that in an attempt to maximize profits, a telemarketing company is conducting an experiment to determine which of four scripted sales pitches generates the best revenue. 1500 different telemarketing calls are randomly assigned to one of the four scripts, and the resulting revenue for each call is recorded.*

    Run an appropriate ANOVA test for this research design.

2)  Regression Analysis: Run a multiple regression analysis on the examrevison.sav dataset, pay particular attention to the 7 Regression diagnostics conditions. This data represents measures from students used to predict how they perform in an exam.
:::

# Telemarketing

## Data Exploration

```{r}
telemarketing <- read_sav("Telemarketing.sav")
telemarketing <- telemarketing |> 
  mutate(
    sales_pitch = as_factor(sales_pitch),
    industry = as_factor(industry),
    region = as_factor(region)
  )
```

@tbl-summary-telemarketing shows that average revenue and variability differ across the four sales pitches, with Script A generating the highest average revenue and Script D the lowest.

```{r}
#| label: tbl-summary-telemarketing
#| tbl-cap: "Summary statistics for `revenue` (n, mean, and standard deviation) across different `sales_pitch` in the telemarketing data"

telemarketing |> 
  drop_na() |> 
  group_by(sales_pitch) |> 
  summarise(
    n = n(),
    avg_revenue = mean(revenue),
    sd_avenue = sd(revenue)
  ) |> 
  kbl(
    col.names = c("sales_pitch", "n", "M", "SD")
  ) |> 
  kable_styling()
```

The distribution of `revenue` across the four `sales_pitch` (Script A, Script B, Script C, and Script D) is visually summarized using violin plots combined with boxplots, as shown in @fig-dist-telemarketing.

```{r}
#| label: fig-dist-telemarketing
#| fig-cap: "Distribution of `revenue` across `sales_pitch` (Script A, Script B, Script C, and Script D) as illustrated by violin and boxplots."
#| fig-asp: 0.5625

telemarketing |> 
  drop_na() |> 
  ggplot(aes(
    x = sales_pitch,
    y = revenue
  )) + 
  geom_point(
    aes(color = sales_pitch),
    show.legend = FALSE,
    position = position_jitter(width = .1),
    size = 2,
    alpha = .5
  ) + 
  geom_violin(
    alpha = .3,
    width = .6,
    show.legend = FALSE
  ) + 
  geom_boxplot(
    width = .4,
    alpha = 0
  ) + 
  stat_summary(
    fun = "mean", geom = "point",
    size = 5, col = "darkred"
  ) + 
  scale_color_brewer(palette = "Dark2") + 
  theme_minimal() + 
  labs(
    x = "Sales Pitch",
    y = "Revenue"
  )
```

## Assumption Checking

-   The outcome variable, revenue, is measured on a ratio scale.

-   The groups are mutually exclusive, with four distinct categories: Script A, Script B, Script C, and Script D.

-   The grouping variable consists of four levels: Script A, Script B, Script C, and Script D.

-   The QQ plots were used to assess the normality of `revenue` distributions for each `sales_pitch` (Script A, Script B, Script C, and Script D). See @fig-qq-plot-telemarketing.

    ```{r}
    #| label: fig-qq-plot-telemarketing
    #| fig-cap: "QQ plot of `revenue` across `sales_pitch`"
    #| fig-asp: 1

    telemarketing |> 
      drop_na() |> 
      ggqqplot(
        x = "revenue",
        color = "sales_pitch"
      ) + 
      facet_wrap(vars(sales_pitch)) + 
      scale_color_brewer(palette = "Dark2") + 
      scale_fill_brewer(palette = "Dark2") + 
      theme_minimal() + 
      theme(
        legend.position = "none"
      )
    ```

    From @fig-qq-plot-telemarketing, it appears that the `revenue` for each `sales_pitch` is likely drawn from a normally distributed population. This observation is supported by the Shapiro-Wilk test results presented in @tbl-normality-test-telemarketing.

    ```{r}
    #| label: tbl-normality-test-telemarketing
    #| tbl-cap: "Shapiro-Wilk test of normality for `revenue` across `sales_pitch`"

    telemarketing |> 
      group_by(sales_pitch) |> 
      shapiro_test(revenue) |> 
      kbl() |> 
      kable_styling()
    ```

    The p-value in @tbl-normality-test-telemarketing is greater than .05 suggests that the `revenue` in each `sales_pitch` follows a normal distribution.

-   @tbl-levene-test-telemarketing presents the results of Levene's test for homogeneity of variances of `revenue` across the different `sales_pitch` groups. Since the p-value is greater than .05, it suggests that the assumption of equal variances is met.

    ```{r}
    #| label: tbl-levene-test-telemarketing
    #| tbl-cap: "Results of Levene test for homogeneity of variance"

    telemarketing |> 
      levene_test(revenue ~ sales_pitch) |> 
      kbl() |> 
      kable_styling()
    ```

## Hypotheses

$H_0$: The average `revenue` is equal across all `sales_pitch` groups.

$H_1$: At least one pair of `sales_pitch` groups has a different average `revenue`.

## Calculating the $F$ statistic

The ANOVA results in @tbl-aov-result-telemarketing show an F-value of 42.505, testing the difference in average `revenue` across the `sales_pitch` groups.

```{r}
#| label: tbl-aov-result-telemarketing
#| tbl-cap: "ANOVA table testing the difference in average `revenue` across `sales_pitch` groups."

aov_telemarketing <- telemarketing |> 
  drop_na() |> 
  anova_test(revenue ~ sales_pitch)
aov_telemarketing |>  kbl() |> 
  kable_styling()
```

## Testing for the significance of $F$

## Interpreting $F$

## Post-hoc test

```{r}
#| label: fig-aov-post-hoc-telemarketing
#| fig-cap: "ANOVA and post-hoc test results for telemarketing data"
#| fig-asp: 1
telemarketing |> 
  ggbetweenstats(
    x = sales_pitch,
    y = revenue,
    type = "parametric",
    pairwise.display = "significant",
    p.adjust.method = "none",
    effsize.type = "eta",
    bf.message = FALSE,
    var.equal = TRUE,
    xlab = "Sales Pitch",
    ylab = "Revenue"
  )
```

# Students' Performance

```{r}
exam <- read_sav("examrevision (1).sav")
```

## Data Exploration

```{r}
#| label: fig-corr-mat-exam
#| fig-cap: "Correlation matrix among all variables in exam data"
#| fig-asp: 0.75

ggcorrmat(
  data = exam,
  cor.vars = score:a_points,
  p.adjust.method = "none"
)
```

```{r}
#| label: tbl-models-summary-exam
#| tbl-cap: "Results of regression analysis on `score`"

# Dependent variable
dep_var <- "score"

# Independent variables
indep_vars <- c("hours", "anxiety", "a_points")

# Generate all possible combinations of independent variables (1, 2, or 3)
all_models <- map(
  1:length(indep_vars),
  ~ combn(indep_vars, .x, simplify = FALSE)
) |> 
  unlist(recursive = FALSE)

# Fit models and extract statistics
results_model <- map_dfr(all_models, function(vars) {
  # Build formula
  formula <- as.formula(paste(dep_var, "~", paste(vars, collapse = " + ")))
  
  # Fit model
  model <- lm(formula, data = exam)
  
  # Extract statistics
  glance_summary <- glance(model)
  
  # Return a summary row
  tibble(
    dependent_variable = dep_var,
    independent_variables = paste(vars, collapse = ", "),
    F_statistic = glance_summary$statistic,
    p_value = glance_summary$p.value,
    R_squared = glance_summary$r.squared,
    df = glance_summary$df,
    df_res = glance_summary$df.residual
  )
})

# Print the summary table
results_model |> 
  kbl() |> 
  kable_styling()
```

## Hypotheses

$H_0$: All regression coefficients are equal to zero (except the intercept).

$H_1$: At least one of the regression coefficients is not equal to zero.

## Assumption Checking

**Correct specification of the model:** It is make sense to predict students' performance score (`score`) with how long they spent on revision (`hours`) and their A-level entry points (`a_points`).

**Linearity:** @fig-linearity-exam shows relationships between `score`, `hours` and `a_points`. From the figures, we can see that the relationship between `hours`, `a_points`, and `score` are linear.

```{r}
#| label: fig-linearity-exam
#| fig-cap: "Linearty verification"
#| fig-subcap:
#|   - "Relationship between `hours` and `score`"
#|   - "Relationship between `a_points` and `score`"
#| fig-asp: 1
#| layout-ncol: 2

exam |> 
  ggplot(aes(x = hours, y = score)) + 
  geom_point(
    size = 3
  ) + 
  stat_ellipse(
    level = .99
  ) + 
  theme_minimal()
exam |> 
  ggplot(aes(x = a_points, y = score)) + 
  geom_point(
    size = 3
  ) + 
  stat_ellipse(
    level = .99
  ) + 
  theme_minimal()
```

**Measurement and normality of dependence variable:** The dependence variable, i.e. `score`, is ratio. From the @fig-qq-plot-score-exam, we can assume that `score` sample is from normally distributed population.

```{r}
#| label: fig-qq-plot-score-exam
#| fig-cap: "Assessing normality for `score`"
ggqqplot(
  data = exam,
  x = "score"
) + 
  theme_minimal()
```

**Absence of multicollinearity:** Here is the correlation coefficient between `hours` and `a_points`.

```{r}
cor(
  exam$hours,
  exam$a_points
)
```

Since the correlation coefficient is less than .8, we infer that there is no multicollinearity between the independent variables.

**Normal distribution of residuals:** @fig-qq-plot-resid-exam shows that the residuals are normally distributed.

```{r}
#| label: fig-qq-plot-resid-exam
#| fig-cap: "Assessing the normality of residuals"
#| fig-asp: 0.5625

reg_model_exam <- lm(
  score ~ hours + a_points,
  data = exam
)
data_model_exam <- tibble(
  score = exam$score,
  fitted = reg_model_exam$fitted.values |> as.numeric(),
  residuals = reg_model_exam$residuals |> as.numeric()
)
ggqqplot(
  data = data_model_exam,
  x = "residuals"
) + 
  theme_minimal()
```

**Homoscedasticity:** @fig-homo-resid-exam shows that the residuals have equal variance across dependence variable.

```{r}
#| label: fig-homo-resid-exam
#| fig-cap: "Assessing homoscedacity of residuals"
#| fig-asp: 0.5625

data_model_exam |> 
  ggplot(aes(x = fitted, y = residuals)) + 
  geom_point() + 
  geom_hline(yintercept = 0) + 
  theme_minimal()
```

## Model

```{r}
summary(reg_model_exam)
```

::: {#fig-3d-model-exam layout-ncol="2"}
![](3d_model_1.png){#fig-3d-model-exam-1}

![](3d_model_2.png){#fig-3d-model-exam-2}

Visualization of the 3D model
:::
